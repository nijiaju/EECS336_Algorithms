\documentclass[12pt,letterpaper]{article}
\usepackage{amsmath, amssymb}
\usepackage{fullpage}
\usepackage{enumitem}
\pagestyle{empty}
\def\pp{\par\noindent}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\baselinestretch}{1.2}
\newcommand{\problem}[1]{ \bigskip \pp \textbf{Problem #1}\par}
\newcommand{\solution}{\pp\textit{Solution:}\par}
\newcommand{\answer}{\medskip\pp\textit{Answer:} }
\newcommand{\lemma}[1]{\medskip\pp\textit{Lemma #1:}}
\newcommand{\proof}{\medskip\pp\textit{Proof:}\par}
\newcommand{\hint}[1] {\par{\footnotesize {\bf Hint:} #1}}
\newcommand{\remark}[1]{\par{\footnotesize {\bf Remark:} #1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\bbZ}    {\mathbb{Z}}
\newcommand{\bbQ}    {\mathbb{Q}}
\newcommand{\bbN}    {\mathbb{N}}
\newcommand{\bbB}    {\mathbb{B}}
\newcommand{\bbR}    {\mathbb{R}}
\newcommand{\bbC}    {\mathbb{C}}
\newcommand{\calP}   {{\cal{P}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\cov}{cov}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\centerline{\bf EECS 336}

\medskip
\centerline{Jiaju Ni}
\centerline{Homework 4}
\bigskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% problem 1
\problem{1}
The greedy algorithm for the longest common subsequence problem proposed in the paper is not correct. This greedy algorithm always pick the symbol that comes earlier in string Y. They claim that it leaves as much opportunity as possible for the remaining symbols to be selected.\par
However, this is not always the case. There are cases that the shorted-sighted greedy strategy will mistakenly discard the correct answer. For example, given two input array,
\[X[A, B, C, D]\]
\[Y[B, A, B, C]\]
In the first iteration, the greedy algorithm will discard $A$ beacuse the occurence of $B$ is earlier in array $Y$. Thus, it will return array $[B, C]$ as the longest common subsequence. However, the correct longest common subsequence is $[A, B, C]$.

% problem 2
\problem{2}
The two cost models will always produce the same optimal tree. Their recursion cases are identical.
\[
	C(i,j)=\underset{i\leq k\leq j}{\min}\left\{C(i,k-1)+C(k+1,j)+\sum_{m=i}^jp_m+\sum_{m=i-1}^jq_m\right\}
\]
Their base cases are slightly different.
\begin{enumerate}
	\item For the cost model in class, the base case is $C(i,i)=q_{i-1}+p_i+q_i$
	\item For the cost model in text book, the base case is $C(i,i)=2q_{i-1}+p_i+2q_i$
\end{enumerate}
Let $C_1(i,j)$ be the cost model in class and $C_2(i,j)$ be the cost model in text book. We can get
\[
	C_2(i,j)-C_1(i,j)=\sum_{m=i}^jq_m
\]
Let $k^*$ be the optimal point that minimize $C_1(i,j)$. We can get for any $k\in[i,j]$,
\begin{align*}
	C_1(i,k-1)+C_1(k,j)&\geq C_1(i,k^*-1)+C_1(k^*,j)\\
	\Leftrightarrow C_1(i,k-1)+\sum_{m=i}^{k-1}q_m+C_1(k,j)+\sum_{m=k}^jq_m&\geq C_1(i,k^*-1)+\sum_{m=i}^{k-1}q_m+C_1(k,j)+\sum_{m=k}^jq_m\\
	\Leftrightarrow C_2(i,k-1)+C_2(k,j)&\geq C_2(i,k^*-1)+C_2(k^*,j)\\
\end{align*}
$k^*$ is also the optimal point that minimize $C_2(i,j)$. Consequently, the two cost models always produce the same optimal tree.	

% problem 3
\problem{3}
\noindent\textbf{Shortest Maximum-Weight Common Subsequence Problem:}\par
The dynamic programming algorithm for this problem uses 2 tables, $L[i, j]$ and $W[i, j]$, the length and the weight of the shortest maximum-weight common subsequence of input array $X[1..i]$ and $Y[1..j]$ $(i\in[0,m], i\in[0,n])$.\par
It has two base cases.
\[
	\begin{cases}
		\text{if } i=0, \text{ then } L(0,j)=0, W(0,j)=0\\
		\text{if } j=0, \text{ then } L(i,0)=0, W(i,0)=0\\
	\end{cases}
\]\par
It has two recursion cases.
\[
	\begin{cases}
		\text{if } x_i=y_i, \text{ then } L(i,j)=1+L(i-1, j-1), W(i,j)=w_i+W(i-1, j-1)\\
		\text{if } x_i\neq y_i, \text{ then } 
		\begin{cases}
			\text{if } W(i-1,j) > W(i,j-1),\\
			\text{then } W(i,j)=W(i-1,j), L(i,j)=L(i-1,j)\\
			\text{if } W(i,j-1) > W(i-1,j),\\
			\text{then } W(i,j)=W(i,j-1), L(i,j)=L(i,j-1)\\
			\text{if } W(i-1,j) = W(i,j-1),\\
			\text{then } W(i,j)=W(i-1,j), L(i,j)=\text{min}\left\{L(i-1,j), L(i,j-1)\right\}\\
		\end{cases}
	\end{cases}
\]\par
\medskip\noindent\textit{Time Complexity}\par
Its time complexity is $O(mn)$, because it creates 2 $m\times n$ tables and each entry of these tables can be calculated in constant time.\par
\medskip\noindent\textit{Correctness}\par
In the case where $x_i=y_j$, this symbol must be the part of the result. Otherwise, we could get a larger weight common sequence by adding $x_i$ to the result we get.(Weights are positive.)\par
In the case where $x_i\neq y_j$, we first compare $W$. And we compare $L$ only when the result of comparing $W$ is equal. This guarantees that we will have a largest weight common subsequence. And get a shortest one among all the largest weight common subsequence results.\par
\medskip
\noindent\textbf{Minimum-Weight Longest Common Subsequence Problem:}\par
The dynamic programming algorithm for this problem uses 2 tables, $L[i, j]$ and $W[i, j]$, the length and the weight of the shortest maximum-weight common subsequence of input array $X[1..i]$ and $Y[1..j]$ $(i\in[0,m], i\in[0,n])$.\par
It has two base cases.
\[
	\begin{cases}
		\text{if } i=0, \text{ then } L(0,j)=0, W(0,j)=0\\
		\text{if } j=0, \text{ then } L(i,0)=0, W(i,0)=0\\
	\end{cases}
\]\par
It has two recursion cases.
\[
	\begin{cases}
		\text{if } x_i=y_j, \text{ then } L(i,j)=1+L(i-1, j-1), W(i,j)=w_i+W(i-1, j-1)\\
		\text{if } x_i\neq y_j, \text{ then } 
		\begin{cases}
			\text{if } L(i-1,j) > L(i,j-1),\\
			\text{then } L(i,j)=W(i-1,j), W(i,j)=L(i-1,j)\\
			\text{if } L(i,j-1) > L(i-1,j),\\
			\text{then } L(i,j)=L(i,j-1), W(i,j)=W(i,j-1)\\
			\text{if } L(i-1,j) = L(i,j-1),\\
			\text{then } L(i,j)=L(i-1,j), W(i,j)=\min\left\{W(i-1,j), W(i,j-1)\right\}\\
		\end{cases}
	\end{cases}
\]\par
\medskip\noindent\textit{Time Complexity}\par
Its time complexity is $O(mn)$, because it creates 2 $m\times n$ tables and each entry of these tables can be calculated in constant time.\par
\medskip\noindent\textit{Correctness}\par
In the case where $x_i=y_j$, this symbol must be the part of the result. Otherwise, we could get a longer common sequence by adding $x_i$ to the result we get.\par
In the case where $x_i\neq y_j$, we first compare $L$. And we compare $W$ only when the result of comparing $L$ is equal. This guarantees that we will have a longest common subsequence. And get a minimum-weight one among all the longest common subsequence results.\par

% problem 4
\problem{4}
The dynamic programming algorithm for this problem uses an array $C[i]$ which is the total cost from the starting point (post 1) to post $i$ $(i\in[1,n])$.\par
It has one base cases.
\[
	C(1)=0
\]\par
Its recusion case is as follows.
\[
	C(i)=\underset{1\leq k\leq i}{\min}(C(k)+f(k,i))
\]\par
\medskip\noindent\textit{Time Complexity}\par
Its time complexity is $O(n^2)$, as we have an array with $n$ elements and we can get the value of each element in at most $n$ operations.\par
\medskip\noindent\textit{Correctness}\par
I'll first prove the correctness of another dynamic programming algorithm for this problem.\par
Let table $C[i, j]$ be the table of minimum costs from post $i$ to post $j$ $(i\in[1,n], j\in[1,n], i\leq j)$. Its base case is straightforward. If $i=j$, then $C(i, j)=0$. Its recursion case is
\[
	C(i,j)=\underset{i\leq k\leq j}{\min}(C(i,k)+C(k,j))
\]\par
The correctness of this dynamic programming algorithm is straight forward. if we already have the minimum cost of $C(i,k)$ and $C(k,j)$ $(k\in[i,j])$, then the minimum cost of $C(i,j)$ must be the smallest one among all the sums $C(i,k)+C(k,j)$, because we only have so many possibilities to travel from $i$ to $j$.\par
This algorithm is not efficient in time and space. It has done replicate works in finding the minimum cost.\par
We know that if $(p, q)$ is in the minimum cost path from $i$ to $j$ ($P_{i,j}$) $(1\leq i\leq p\leq q \leq j\leq n)$, then it must be in the minimum cost path from $i$ to $q$ ($P_{i,q}$). Otherwise, assume we have another minimum cost path $P_{i,q}'$ from $i$ to $q$ that do not contain $(p,q)$, then we can get a new minimum cost path from $i$ to $j$ which does not contain $(p,q)$ via concatenating $P_{i,j}'$ and $P_{q,j}$. This result contradicts with the precondition.\par
Therefore, we only need to check $C(1,k)+f(k,j)$ for all possible $k$ when finding the minimum cost $C(j)$. Other possible paths from $k$ to $j$ will be checked in other recursion cases. For exmaple, if $(p,q)$ is in a path from $k$ to $j$, as $q$ is less or equal than $j$, we will have it checked when calculating $C(q)$.\par
Assume we have a series of minimum costs $C(1)..C(i)$. Then $C(i+1)=\underset{1\leq k\leq i}{\min}(C(k)+f(k,i+1))$. For each interval $[p,q]$ in $[k,i+1]$, there will be two cases.
\begin{enumerate}
	\item if $q<i+1$, then it will be checked in $C(q)$, and it will contribute to $C(q)$ if and only if it is in the minimum cost path from $1$ to $q$.\\
	\item if $q=i+1$, then it will be checked in this iteration, and it will contribute to $C(i+1)$ if $C(q)+f(q,i)$ is minimum value among all valid $q$. Thus, it must be the minimum value from $1$ to $i+1$.\\
\end{enumerate}
The base case is apprantly correct. Apply induction to this and we can conlcude that $C(n)$ must be the minimum cost from $1$ to $n$.

% problem 5
\problem{5}
First of all, we need to sort the points by their x-coordinate. And the discussion below assume that the points are sorted.\par
\medskip\noindent\textit{Table}\par
In the 4-tonic tour problem, there are 4 pivot points, one of them is point $1$, on of them is point $N$. Denote the other two pivot points $a$ and $b$ respectively. The dynameic programming algorithm for this problem uses an table $X[i,j,k,l]$ to denote the minimum sum of four paths. For any fixed points $a$ and $b$, these paths are path $1$ to $i$, path $1$ to $j$, path $a$ to $k$ and path $a$ to $l$.\par
This is a $n\times n\times n\times n$ table. We initialize each entry in this table to be positive infinity.\par
\medskip\noindent\textit{Base Case}\par
For any fixed point $a$ and $b$, $X[1,1,a,a]=0$.\par
\medskip\noindent\textit{Recursion Case}\par
For any fixed point $a$, $b$ and $n$, let $p$ be the next point that will be added into current paths. ($p\in(1, n), p\neq a, p\neq b$).\par
\begin{enumerate}
	\item If $1<p<a$, then $p$ must be $1+\max\left\{i,j\right\}$. Update the table by following equations.
		\begin{align*}
			X(p,j,a,a)&=\min\left\{X(i,j,a,a)+d(p,i), X(p,j,a,a)\right\}\\
			X(i,p,a,a)&=\min\left\{X(i,j,a,a)+d(p,j), X(p,j,a,a)\right\}\\
		\end{align*}
	\item If $a<p<b$, then $p$ must be $1+\max\left\{i,j,k,l\right\}$. Update the table by follwing equations.
		\begin{align*}
			X(p,j,k,l)&=\min\left\{X(i,j,k,l)+d(p,i), X(p,j,k,l)\right\}\\
			X(i,p,k,l)&=\min\left\{X(i,j,k,l)+d(p,j), X(i,p,k,l)\right\}\\
			X(i,j,p,l)&=\min\left\{X(i,j,k,l)+d(p,k), X(i,j,p,l)\right\}\\
			X(i,j,k,p)&=\min\left\{X(i,j,k,l)+d(p,l), X(i,j,k,p)\right\}\\
		\end{align*}
	\item if $p=b$, then update the table by following equations.
		\begin{align*}
			X(i,b,k,b)&=\min\left\{X(i,j,k,l)+d(b,j)+d(b,l),X(i,b,k,b)\right\}\\
			X(i,b,b,l)&=\min\left\{X(i,j,k,l)+d(b,j)+d(b,k),X(i,b,b,l)\right\}\\
			X(b,j,b,l)&=\min\left\{X(i,j,k,l)+d(b,i)+d(b,k),X(b,j,b,l)\right\}\\
			X(b,j,k,b)&=\min\left\{X(i,j,k,l)+d(b,i)+d(b,l),X(b,j,k,b)\right\}\\
		\end{align*}
	\item if $b<p<n$, then $p$ must be $1+\max\left\{j,l\right\}$. Update the table by following equations.
		\begin{align*}
			X(b,j,b,p)&=\min\left\{X(b,j,b,l)+d(p,l),X(b,j,b,l)\right\}\\
			X(b,p,b,l)&=\min\left\{X(b,j,b,l)+d(p,j),X(b,j,b,l)\right\}\\
		\end{align*}
	\item if $p=n$, then update the table by following equations.
		\begin{align*}
			X(b,n,b,n)=\min\left\{X(b,j,b,l)+d(j,n)+d(l,n), X(b,n,b,n)\right\}\\
		\end{align*}
\end{enumerate}
\medskip\noindent\textit{Time Complexity}\par
For every fixed $a$, $b$ and $n$, we add new point $p$ from $2$ to $n-1$. For each $p$, the recursion case takes constant time. So, the time complexity for each fixed $a$, $b$ and $n$ is $O(n)$.\par
As $a\in(1,n-1)$, $b\in(2,n)$ and $n\in[4,N]$, we can see there are three for loops here and each loop has less than $N$ iterations. Therefore, the total time complexity is $O(n^4)$.\par
\medskip\noindent\textit{Correctness}\par
We split a 4-tonic tour into 4 paths by the pivots $1$, $a$, $b$ and $n$. For each new rightmost point $p$, it must be add into one of the four paths. According to the recursion case, we can get the minimum sum of the paths with the given fix points.\par
In order to get the minimum value among all $a$, $b$ and $n$, we must also compare it with the historical minimum sum calculated by other combinations of fix pivot points.\par
Thus, we can guaranteed that the final result $\min_{i=1}^N\left\{X(i,N,i,N)\right\}$ must be the minimum 4-tonic tour among all possible pivot points.\par
\end{document}
